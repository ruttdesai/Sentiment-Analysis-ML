{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Twitter Sentiment Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPHs/owafOV+5TXT9sX2qQm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ruttdesai/Twitter-Sentiment-Analysis/blob/main/Twitter_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPDFkAhrDRK8"
      },
      "source": [
        "# **TWITTER SENTIMENT ANALYSIS**\n",
        "      - THE CLASSIFICATION OF THE TWEETS IS DONE INTO POSITIVE,NEGATIVE\n",
        "        AND NEUTRAL SENTIMENTS.\n",
        "      - *MADE BY RUTT DESAI*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyPjHpG6BZbZ"
      },
      "source": [
        "# **STEPS IN THE MODEL**\n",
        "\n",
        "1. Installing the required methods for the model\n",
        "2. Installing the Required Libraries\n",
        "3. Twiter Authentication\n",
        "4. Preprocessing the Tweets\n",
        "5. Classification of the Tweets\n",
        "6. Fetching and Parsing the Tweets\n",
        "7. Main Function of the Model\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lzeAOoc6WoH",
        "outputId": "a70d636b-0855-4cf0-8fc9-824912fc7c8b"
      },
      "source": [
        "#                         1.   Installing the required methods for the model\n",
        "!pip install tweepy --quiet\n",
        "!pip install textblob --quiet\n",
        "!python -m textblob.download_corpora --quiet"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Package conll2000 is already up-to-date!\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n",
            "Finished.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37kZGXNq6ehs"
      },
      "source": [
        "#                         2.   Installing the Required Libraries\n",
        "import re  #Importing RegEx\n",
        "import tweepy #Importing twwepy for gtting tweets\n",
        "from tweepy import OAuthHandler #Using For getting authentication\n",
        "from textblob import TextBlob #Importing textblob for processing textual data"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxfli2iX72VO"
      },
      "source": [
        "#                         3.   TWITTER AUTHENTICATION\n",
        "class TwitterClient(object):\n",
        "  def __init__(self):\n",
        "      # keys and tokens from the Twitter Dev Console\n",
        "        consumer_key = 'QJylHgH8XzbBsLzO0yCZQR1vv'\n",
        "        consumer_secret = 'm4i2Uvs0tFhwcwZYZvLP4GzxDnO1RA4mBzQjb0UD3zDhx9PLMj'\n",
        "        access_token = '1206779143460835330-ricd0Az3oIR91mIFyzAJSWHKnKdfw4'\n",
        "        access_token_secret = 'tD1HZ8CPqfZBwSXONgjVr953maTVX44fsQknmHGkj7mBw'\n",
        "  \n",
        "      # attempt authentication\n",
        "        try:\n",
        "          # create OAuthHandler object\n",
        "            self.auth = OAuthHandler(consumer_key, consumer_secret)\n",
        "          # set access token and secret\n",
        "            self.auth.set_access_token(access_token, access_token_secret)\n",
        "          # create tweepy API object to fetch tweets\n",
        "            self.api = tweepy.API(self.auth)\n",
        "        except:\n",
        "            print(\"Error: Authentication Failed\")\n",
        "\n",
        "#                        4.    PREPROCESSING THE TWEETS\n",
        "  def clean_tweet(self, tweet):\n",
        "        #function to clean tweet text by removing links and special characters using regex statements.\n",
        "          return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
        "\n",
        "#                        5.   CLASSIFICATION OF THE TWEETS\n",
        "  def get_tweet_sentiment(self, tweet):\n",
        "        #function to classify sentiment of passed tweet using textblob's sentiment method\n",
        "\n",
        "        # creating TextBlob object of tweet text\n",
        "          analysis = TextBlob(self.clean_tweet(tweet))\n",
        "        # setting the sentiments\n",
        "          if analysis.sentiment.polarity > 0:\n",
        "            return 'positive'\n",
        "          elif analysis.sentiment.polarity == 0:\n",
        "            return 'neutral'\n",
        "          else:\n",
        "            return 'negative'\n",
        "\n",
        "#                        6.    FETCHING AND PARSING THE TWEETS\n",
        "  def get_tweets(self, query, count = 10):\n",
        "        #function to fetch tweets and parse them.\n",
        "        \n",
        "        # empty list to store parsed tweets\n",
        "          tweets = []\n",
        "  \n",
        "          try:\n",
        "            # call twitter api to fetch tweets\n",
        "              fetched_tweets = self.api.search(q = query, count = count)\n",
        "  \n",
        "            # parsing tweets one by one\n",
        "              for tweet in fetched_tweets:\n",
        "                # empty dictionary to store required params of a tweet\n",
        "                  parsed_tweet = {}\n",
        "  \n",
        "                # saving text of tweet\n",
        "                  parsed_tweet['text'] = tweet.text\n",
        "                # saving sentiment of tweet\n",
        "                  parsed_tweet['sentiment'] = self.get_tweet_sentiment(tweet.text)\n",
        "  \n",
        "                # appending parsed tweet to tweets list\n",
        "                  if tweet.retweet_count > 0:\n",
        "                    # if tweet has retweets, ensure that it is appended only once\n",
        "                      if parsed_tweet not in tweets:\n",
        "                          tweets.append(parsed_tweet)\n",
        "                  else:\n",
        "                      tweets.append(parsed_tweet)\n",
        "\n",
        "            # return parsed tweets\n",
        "              return tweets\n",
        "  \n",
        "          except tweepy.TweepError as e:\n",
        "            # print any occured errors\n",
        "              print(\"Error : \" + str(e))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LncpPOt3-jvV",
        "outputId": "6b1db64e-f153-4b8e-8413-32c935c5703b"
      },
      "source": [
        "#                        7.     MAIN FUNCTION OF THE MODEL\n",
        "def main():\n",
        "  # creating object of TwitterClient Class\n",
        "    api = TwitterClient()\n",
        "  # calling function to get tweets\n",
        "    tweets = api.get_tweets(query = 'Rahul Gandhi', count = 150)\n",
        "  \n",
        "  # picking positive tweets from tweets\n",
        "    ptweets = [tweet for tweet in tweets if tweet['sentiment'] == 'positive']\n",
        "  # percentage of positive tweets\n",
        "    print(\"Positive tweets percentage: {} %\".format(100*len(ptweets)/len(tweets)))\n",
        "  # picking negative tweets from tweets\n",
        "    ntweets = [tweet for tweet in tweets if tweet['sentiment'] == 'negative']\n",
        "  # percentage of negative tweets\n",
        "    print(\"Negative tweets percentage: {} %\".format(100*len(ntweets)/len(tweets)))\n",
        "  # percentage of neutral tweets\n",
        "    print(\"Neutral tweets percentage: {} % \\\n",
        "        \".format(100*(len(tweets) -(len( ntweets )+len( ptweets)))/len(tweets)))\n",
        "  \n",
        "  # printing first 5 positive tweets\n",
        "    print(\"\\n\\nPositive tweets:\")\n",
        "    for tweet in ptweets[:10]:\n",
        "        print(tweet['text'])\n",
        "  \n",
        "  # printing first 5 negative tweets\n",
        "    print(\"\\n\\nNegative tweets:\")\n",
        "    for tweet in ntweets[:10]:\n",
        "        print(tweet['text'])\n",
        "  \n",
        "if __name__ == \"__main__\":\n",
        "  # calling main function\n",
        "    main()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive tweets percentage: 19.51219512195122 %\n",
            "Negative tweets percentage: 29.26829268292683 %\n",
            "Neutral tweets percentage: 51.21951219512195 %         \n",
            "\n",
            "\n",
            "Positive tweets:\n",
            "RT @SanggitaT: India has become a danger to the whole world -- Rahul Gandhi.. \n",
            "\n",
            "Is the world in danger or is India in danger because of Rah…\n",
            "RT @Ra_Bies: Sanjukta, congress is always doing good job but most of people are fools &amp; don’t understand. Common Indians are uneducated unc…\n",
            "RT @newspaperwallah: Criticize Rahul Gandhi, the Congress and the UPA as much as you like. But I don't believe they would ever suppress the…\n",
            "RT @RMCpost: But Narendra Modi has more shawls than Rahul Gandhi... RG ke paas kitna hai?... https://t.co/P9DUkCozCQ\n",
            "Love how @RanaAyyub writes. \n",
            "\n",
            "Case in point? https://t.co/Eh77oYnpjx\n",
            "RT @ShailendraD2020: ‘Toolkit’ Modi Ji नहीं, Rahul Gandhi लेकर भागे हैं ! हाँ, मैं हूँ मोदी भक्त.. कोई शक? | Toolkit Case 😃\n",
            "Watch Full Vide…\n",
            "RT @Sootradhar: Target Gujarat is one more thing in the tool kit. \n",
            "\n",
            "This explains Rahul Gandhi's continous attacks on Gujarati owned busine…\n",
            "RT @samitas53375357: Why is Rahul Gandhi calling a virus Indian variant?  \n",
            "Why so much hatred towards the India and want to break our natio…\n",
            "\n",
            "\n",
            "Negative tweets:\n",
            "RT @vijaygajera: Another Big Expose on Rahul Gandi\n",
            "\n",
            "Thread\n",
            "\n",
            "Yesterday I have exposed about Rahul Gandhi’s UK Company Backops Limited, Today…\n",
            "RT @amitmalviya: The Congress may be desperate to call their toolkit fake and disown but can they disown Rahul Gandhi who has been repeated…\n",
            "RT @vivekagnihotri: In India, being a ‘political idiot’ is not a crime. And, Rahul Gandhi takes maximum advantage of it.\n",
            "RT @rishibagree: Rahul Gandhi is religiously following #CongressToolKit while his sister Priyanka Vadra calling it Fake https://t.co/uJHt4W…\n",
            "RT @vijaygajera: Everyone knows that Ulrik MCKNIGHT was Rahul Gandi’s partner in UK firm Backops Limited but do you know he was also direct…\n",
            "RT @Aaabshar: Rahul Gandhi’s tribute to late @SATAVRAJEEV live now. Do watch \n",
            "\n",
            "https://t.co/iSx7mCGpKS\n",
            "RT @mvmeet: In Madhya Pradesh, a 40-year-old woman was found dead at Congress MLA Umang Singhar's bungalow\n",
            "\n",
            "The woman was regularly meeting…\n",
            "RT @vijaygajera: Wait for few minutes, coming with big expose of Rahul Gandhi🙏\n",
            "#CongressToolKit\n",
            "#CongressToolkitExposed\n",
            "#CongressToolKitExpose\n",
            "#Stop_Vulture_Journalism\n",
            "#Arrest_Rahul_Gandhi… https://t.co/FqVx4znP43\n",
            "RT @Agrimonious: If you think my obsession with Fawad Khan is bad, you should see Smriti Irani's Rahul Gandhi tweets.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}